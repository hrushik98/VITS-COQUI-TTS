{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNLygawX4s7IVHWU0FEWJlf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hrushik98/VITS-COQUI-TTS/blob/dev/VITS_COQUI_TTS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "follow me on github: @hrushik98"
      ],
      "metadata": {
        "id": "JNAbwX7oezU4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clone my forked TTS repo and install the requirements"
      ],
      "metadata": {
        "id": "-9t0tFkGdCUg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W7dMTCiuKmU5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "45f9c9fd-993e-4901-9c4c-859bdb868227"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'VITS-COQUI-TTS'...\n",
            "remote: Enumerating objects: 26725, done.\u001b[K\n",
            "remote: Counting objects: 100% (615/615), done.\u001b[K\n",
            "remote: Compressing objects: 100% (235/235), done.\u001b[K\n",
            "remote: Total 26725 (delta 380), reused 526 (delta 366), pack-reused 26110\u001b[K\n",
            "Receiving objects: 100% (26725/26725), 129.37 MiB | 29.33 MiB/s, done.\n",
            "Resolving deltas: 100% (19274/19274), done.\n",
            "/content/VITS-COQUI-TTS\n",
            "Obtaining file:///content/VITS-COQUI-TTS\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting cython==0.29.30 (from TTS==0.15.6)\n",
            "  Using cached Cython-0.29.30-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (1.9 MB)\n",
            "Requirement already satisfied: scipy>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from TTS==0.15.6) (1.10.1)\n",
            "Requirement already satisfied: torch>=1.7 in /usr/local/lib/python3.10/dist-packages (from TTS==0.15.6) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (from TTS==0.15.6) (2.0.2+cu118)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.10/dist-packages (from TTS==0.15.6) (0.12.1)\n",
            "Requirement already satisfied: librosa==0.10.0.* in /usr/local/lib/python3.10/dist-packages (from TTS==0.15.6) (0.10.0.post2)\n",
            "Collecting inflect==5.6.0 (from TTS==0.15.6)\n",
            "  Downloading inflect-5.6.0-py3-none-any.whl (33 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from TTS==0.15.6) (4.65.0)\n",
            "Collecting anyascii (from TTS==0.15.6)\n",
            "  Downloading anyascii-0.3.2-py3-none-any.whl (289 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.9/289.9 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from TTS==0.15.6) (6.0)\n",
            "Requirement already satisfied: fsspec>=2021.04.0 in /usr/local/lib/python3.10/dist-packages (from TTS==0.15.6) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from TTS==0.15.6) (3.8.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from TTS==0.15.6) (23.1)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.10/dist-packages (from TTS==0.15.6) (2.2.5)\n",
            "Collecting pysbd (from TTS==0.15.6)\n",
            "  Downloading pysbd-0.3.4-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting umap-learn==0.5.1 (from TTS==0.15.6)\n",
            "  Downloading umap-learn-0.5.1.tar.gz (80 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.9/80.9 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from TTS==0.15.6) (1.5.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from TTS==0.15.6) (3.7.1)\n",
            "Collecting trainer (from TTS==0.15.6)\n",
            "  Downloading trainer-0.0.27-py3-none-any.whl (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.3/48.3 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting coqpit>=0.0.16 (from TTS==0.15.6)\n",
            "  Downloading coqpit-0.0.17-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: jieba in /usr/local/lib/python3.10/dist-packages (from TTS==0.15.6) (0.42.1)\n",
            "Collecting pypinyin (from TTS==0.15.6)\n",
            "  Downloading pypinyin-0.49.0-py2.py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m46.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mecab-python3==1.0.6 (from TTS==0.15.6)\n",
            "  Downloading mecab_python3-1.0.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (581 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m581.6/581.6 kB\u001b[0m \u001b[31m57.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting unidic-lite==1.0.8 (from TTS==0.15.6)\n",
            "  Downloading unidic-lite-1.0.8.tar.gz (47.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.4/47.4 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gruut[de,es,fr]==2.2.3 (from TTS==0.15.6)\n",
            "  Downloading gruut-2.2.3.tar.gz (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.5/73.5 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting jamo (from TTS==0.15.6)\n",
            "  Downloading jamo-0.4.1-py3-none-any.whl (9.5 kB)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from TTS==0.15.6) (3.8.1)\n",
            "Collecting g2pkk>=0.1.1 (from TTS==0.15.6)\n",
            "  Downloading g2pkk-0.1.2-py3-none-any.whl (25 kB)\n",
            "Collecting bangla==0.0.2 (from TTS==0.15.6)\n",
            "  Downloading bangla-0.0.2-py2.py3-none-any.whl (6.2 kB)\n",
            "Collecting bnnumerizer (from TTS==0.15.6)\n",
            "  Downloading bnnumerizer-0.0.2.tar.gz (4.7 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting bnunicodenormalizer==0.1.1 (from TTS==0.15.6)\n",
            "  Downloading bnunicodenormalizer-0.1.1.tar.gz (38 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting k-diffusion (from TTS==0.15.6)\n",
            "  Downloading k_diffusion-0.0.15-py3-none-any.whl (25 kB)\n",
            "Collecting einops (from TTS==0.15.6)\n",
            "  Downloading einops-0.6.1-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers (from TTS==0.15.6)\n",
            "  Downloading transformers-4.30.2-py3-none-any.whl (7.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m82.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting encodec (from TTS==0.15.6)\n",
            "  Downloading encodec-0.1.1.tar.gz (3.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m60.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting numpy==1.22.0 (from TTS==0.15.6)\n",
            "  Using cached numpy-1.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
            "Collecting numba==0.57.0 (from TTS==0.15.6)\n",
            "  Downloading numba-0.57.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m88.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Babel<3.0.0,>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from gruut[de,es,fr]==2.2.3->TTS==0.15.6) (2.12.1)\n",
            "Collecting dateparser~=1.1.0 (from gruut[de,es,fr]==2.2.3->TTS==0.15.6)\n",
            "  Downloading dateparser-1.1.8-py2.py3-none-any.whl (293 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m293.8/293.8 kB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gruut-ipa<1.0,>=0.12.0 (from gruut[de,es,fr]==2.2.3->TTS==0.15.6)\n",
            "  Downloading gruut-ipa-0.13.0.tar.gz (101 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gruut_lang_en~=2.0.0 (from gruut[de,es,fr]==2.2.3->TTS==0.15.6)\n",
            "  Downloading gruut_lang_en-2.0.0.tar.gz (15.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.2/15.2 MB\u001b[0m \u001b[31m68.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting jsonlines~=1.2.0 (from gruut[de,es,fr]==2.2.3->TTS==0.15.6)\n",
            "  Downloading jsonlines-1.2.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Collecting networkx<3.0.0,>=2.5.0 (from gruut[de,es,fr]==2.2.3->TTS==0.15.6)\n",
            "  Downloading networkx-2.8.8-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m100.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting num2words<1.0.0,>=0.5.10 (from gruut[de,es,fr]==2.2.3->TTS==0.15.6)\n",
            "  Downloading num2words-0.5.12-py3-none-any.whl (125 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.2/125.2 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-crfsuite~=0.9.7 (from gruut[de,es,fr]==2.2.3->TTS==0.15.6)\n",
            "  Downloading python_crfsuite-0.9.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (993 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m993.5/993.5 kB\u001b[0m \u001b[31m66.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gruut_lang_de~=2.0.0 (from gruut[de,es,fr]==2.2.3->TTS==0.15.6)\n",
            "  Downloading gruut_lang_de-2.0.0.tar.gz (18.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gruut_lang_fr~=2.0.0 (from gruut[de,es,fr]==2.2.3->TTS==0.15.6)\n",
            "  Downloading gruut_lang_fr-2.0.2.tar.gz (10.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m111.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gruut_lang_es~=2.0.0 (from gruut[de,es,fr]==2.2.3->TTS==0.15.6)\n",
            "  Downloading gruut_lang_es-2.0.0.tar.gz (31.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa==0.10.0.*->TTS==0.15.6) (3.0.0)\n",
            "INFO: pip is looking at multiple versions of librosa to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting librosa==0.10.0.* (from TTS==0.15.6)\n",
            "  Downloading librosa-0.10.0.post1-py3-none-any.whl (252 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.0/253.0 kB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading librosa-0.10.0-py3-none-any.whl (252 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.9/252.9 kB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa==0.10.0.*->TTS==0.15.6) (1.2.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa==0.10.0.*->TTS==0.15.6) (1.3.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa==0.10.0.*->TTS==0.15.6) (4.4.2)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa==0.10.0.*->TTS==0.15.6) (1.6.0)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa==0.10.0.*->TTS==0.15.6) (0.3.5)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa==0.10.0.*->TTS==0.15.6) (4.7.1)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa==0.10.0.*->TTS==0.15.6) (0.3)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa==0.10.0.*->TTS==0.15.6) (1.0.5)\n",
            "Collecting llvmlite<0.41,>=0.40.0dev0 (from numba==0.57.0->TTS==0.15.6)\n",
            "  Downloading llvmlite-0.40.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.1/42.1 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pynndescent>=0.5 (from umap-learn==0.5.1->TTS==0.15.6)\n",
            "  Downloading pynndescent-0.5.10.tar.gz (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m61.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile->TTS==0.15.6) (1.15.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->TTS==0.15.6) (3.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->TTS==0.15.6) (1.11.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->TTS==0.15.6) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->TTS==0.15.6) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7->TTS==0.15.6) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7->TTS==0.15.6) (16.0.6)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->TTS==0.15.6) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->TTS==0.15.6) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->TTS==0.15.6) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->TTS==0.15.6) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->TTS==0.15.6) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->TTS==0.15.6) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->TTS==0.15.6) (1.3.1)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from flask->TTS==0.15.6) (2.3.6)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from flask->TTS==0.15.6) (2.1.2)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from flask->TTS==0.15.6) (8.1.4)\n",
            "Collecting accelerate (from k-diffusion->TTS==0.15.6)\n",
            "  Downloading accelerate-0.21.0-py3-none-any.whl (244 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.2/244.2 kB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting clean-fid (from k-diffusion->TTS==0.15.6)\n",
            "  Downloading clean_fid-0.1.35-py3-none-any.whl (26 kB)\n",
            "Collecting clip-anytorch (from k-diffusion->TTS==0.15.6)\n",
            "  Downloading clip_anytorch-2.5.2-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m86.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jsonmerge (from k-diffusion->TTS==0.15.6)\n",
            "  Downloading jsonmerge-1.9.1.tar.gz (34 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting kornia (from k-diffusion->TTS==0.15.6)\n",
            "  Downloading kornia-0.6.12-py2.py3-none-any.whl (653 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m653.4/653.4 kB\u001b[0m \u001b[31m49.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from k-diffusion->TTS==0.15.6) (8.4.0)\n",
            "Collecting resize-right (from k-diffusion->TTS==0.15.6)\n",
            "  Downloading resize_right-0.0.2-py3-none-any.whl (8.9 kB)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from k-diffusion->TTS==0.15.6) (0.19.3)\n",
            "Collecting torchdiffeq (from k-diffusion->TTS==0.15.6)\n",
            "  Downloading torchdiffeq-0.2.3-py3-none-any.whl (31 kB)\n",
            "Collecting torchsde (from k-diffusion->TTS==0.15.6)\n",
            "  Downloading torchsde-0.2.5-py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.2/59.2 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from k-diffusion->TTS==0.15.6) (0.15.2+cu118)\n",
            "Collecting wandb (from k-diffusion->TTS==0.15.6)\n",
            "  Downloading wandb-0.15.5-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m79.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->TTS==0.15.6) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->TTS==0.15.6) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->TTS==0.15.6) (4.40.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->TTS==0.15.6) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->TTS==0.15.6) (3.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->TTS==0.15.6) (2.8.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->TTS==0.15.6) (2022.10.31)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->TTS==0.15.6) (2022.7.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from trainer->TTS==0.15.6) (5.9.5)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from trainer->TTS==0.15.6) (2.12.3)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers->TTS==0.15.6)\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers->TTS==0.15.6) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers->TTS==0.15.6)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m92.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers->TTS==0.15.6)\n",
            "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m66.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile->TTS==0.15.6) (2.21)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.10/dist-packages (from dateparser~=1.1.0->gruut[de,es,fr]==2.2.3->TTS==0.15.6) (5.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7->TTS==0.15.6) (2.1.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from jsonlines~=1.2.0->gruut[de,es,fr]==2.2.3->TTS==0.15.6) (1.16.0)\n",
            "Collecting docopt>=0.6.2 (from num2words<1.0.0,>=0.5.10->gruut[de,es,fr]==2.2.3->TTS==0.15.6)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa==0.10.0.*->TTS==0.15.6) (1.4.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->TTS==0.15.6) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->TTS==0.15.6) (2023.5.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->TTS==0.15.6) (3.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa==0.10.0.*->TTS==0.15.6) (3.1.0)\n",
            "Collecting ftfy (from clip-anytorch->k-diffusion->TTS==0.15.6)\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jsonschema<=4.17.3,>2.4.0 in /usr/local/lib/python3.10/dist-packages (from jsonmerge->k-diffusion->TTS==0.15.6) (4.3.3)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->k-diffusion->TTS==0.15.6) (2.25.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->k-diffusion->TTS==0.15.6) (2023.7.10)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->k-diffusion->TTS==0.15.6) (1.4.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7->TTS==0.15.6) (1.3.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer->TTS==0.15.6) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer->TTS==0.15.6) (1.56.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer->TTS==0.15.6) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer->TTS==0.15.6) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer->TTS==0.15.6) (3.4.3)\n",
            "Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer->TTS==0.15.6) (3.20.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer->TTS==0.15.6) (67.7.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer->TTS==0.15.6) (0.7.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer->TTS==0.15.6) (0.40.0)\n",
            "Collecting boltons>=20.2.1 (from torchsde->k-diffusion->TTS==0.15.6)\n",
            "  Downloading boltons-23.0.0-py2.py3-none-any.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting trampoline>=0.1.2 (from torchsde->k-diffusion->TTS==0.15.6)\n",
            "  Downloading trampoline-0.1.2-py3-none-any.whl (5.2 kB)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb->k-diffusion->TTS==0.15.6)\n",
            "  Downloading GitPython-3.1.32-py3-none-any.whl (188 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.5/188.5 kB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentry-sdk>=1.0.0 (from wandb->k-diffusion->TTS==0.15.6)\n",
            "  Downloading sentry_sdk-1.28.1-py2.py3-none-any.whl (214 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m214.7/214.7 kB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb->k-diffusion->TTS==0.15.6)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting pathtools (from wandb->k-diffusion->TTS==0.15.6)\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting setproctitle (from wandb->k-diffusion->TTS==0.15.6)\n",
            "  Downloading setproctitle-1.3.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb->k-diffusion->TTS==0.15.6)\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->trainer->TTS==0.15.6) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->trainer->TTS==0.15.6) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->trainer->TTS==0.15.6) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard->trainer->TTS==0.15.6) (1.3.1)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema<=4.17.3,>2.4.0->jsonmerge->k-diffusion->TTS==0.15.6) (0.19.3)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from ftfy->clip-anytorch->k-diffusion->TTS==0.15.6) (0.2.6)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb->k-diffusion->TTS==0.15.6)\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->trainer->TTS==0.15.6) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard->trainer->TTS==0.15.6) (3.2.2)\n",
            "Building wheels for collected packages: TTS, bnunicodenormalizer, umap-learn, unidic-lite, bnnumerizer, encodec, gruut-ipa, gruut_lang_de, gruut_lang_en, gruut_lang_es, gruut_lang_fr, pynndescent, gruut, jsonmerge, docopt, pathtools\n",
            "  Building editable for TTS (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for TTS: filename=TTS-0.15.6-0.editable-cp310-cp310-linux_x86_64.whl size=9920 sha256=5dd6a8765349a996273a9e1e20da3b22aae8a104b9364da5e54694d55759dc5d\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-a0qefw2o/wheels/e9/5f/20/1b1f56a8477633d5f07d1d0b4a31d3bfcb77da7d6c7f3837f5\n",
            "  Building wheel for bnunicodenormalizer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bnunicodenormalizer: filename=bnunicodenormalizer-0.1.1-py3-none-any.whl size=21895 sha256=cfd0aa1c51ef82995a16f3c035b1f0f529bf3f0a8ace340b8ade898582b41c46\n",
            "  Stored in directory: /root/.cache/pip/wheels/b4/f6/01/9e68ecec7c7ea85fc9431cfac42eba1c5a5f6debe5070de5c7\n",
            "  Building wheel for umap-learn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for umap-learn: filename=umap_learn-0.5.1-py3-none-any.whl size=76548 sha256=f4c77929e95ad76a11a515041bae8450ee5361da3977cb4c45f2c28434c217cb\n",
            "  Stored in directory: /root/.cache/pip/wheels/69/21/8e/802cb9c4c606a67139f538cb17bf3bf1b98b739a7900469953\n",
            "  Building wheel for unidic-lite (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for unidic-lite: filename=unidic_lite-1.0.8-py3-none-any.whl size=47658818 sha256=3cf70b93e917c583efdd0f47d340374cdc11726b46efcdf62937c0f47ba83a28\n",
            "  Stored in directory: /root/.cache/pip/wheels/89/e8/68/f9ac36b8cc6c8b3c96888cd57434abed96595d444f42243853\n",
            "  Building wheel for bnnumerizer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bnnumerizer: filename=bnnumerizer-0.0.2-py3-none-any.whl size=5259 sha256=bf91a89b68d38f991d5585874e8b49f84ad73000ebc3dffdddfaf2bd9f9cd670\n",
            "  Stored in directory: /root/.cache/pip/wheels/59/6b/e8/223172e7d5c9f72df3ea1a0d9258f3a8ab5b28e827728edef5\n",
            "  Building wheel for encodec (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for encodec: filename=encodec-0.1.1-py3-none-any.whl size=45760 sha256=23892255070da04738d512d868fa10f0a7d98f71444ec51e0e58b84825e23573\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/36/cb/81af8b985a5f5e0815312d5e52b41263237af07b977e6bcbf3\n",
            "  Building wheel for gruut-ipa (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut-ipa: filename=gruut_ipa-0.13.0-py3-none-any.whl size=104870 sha256=65f3392213946b77da9c03b20f0ddcdbbb91194afa5ae77adc2efb13d8d710bb\n",
            "  Stored in directory: /root/.cache/pip/wheels/7b/18/49/e4f500ecdf0babe757953f844e4d7cd1ea81c5503c09bfe984\n",
            "  Building wheel for gruut_lang_de (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut_lang_de: filename=gruut_lang_de-2.0.0-py3-none-any.whl size=18498182 sha256=49e566b38578dbb3bd7dac5bbabc117e0eb890ba5117b77be3ccd241c2fa66ed\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/9a/05/cfce98f0c41a1a540f15708c4a02df190b82d84cf91ef6bc7f\n",
            "  Building wheel for gruut_lang_en (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut_lang_en: filename=gruut_lang_en-2.0.0-py3-none-any.whl size=15297178 sha256=9b2d6331f979311809cef8d20adda170de0844c8d56c51d26f0edf8b3e6f6eb1\n",
            "  Stored in directory: /root/.cache/pip/wheels/10/9c/fb/77c655a9fbd78cdb9935d0ab65d80ddd0a3bcf7dbe18261650\n",
            "  Building wheel for gruut_lang_es (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut_lang_es: filename=gruut_lang_es-2.0.0-py3-none-any.whl size=32173796 sha256=e6c3fec00e869acb3351e5379e8d9f04e3dfac3b9bb3f4fd0f3a4393fbc136fd\n",
            "  Stored in directory: /root/.cache/pip/wheels/9b/0a/90/788d92c07744b329b9283e37b29b064f5db6b1bb0442a1a19b\n",
            "  Building wheel for gruut_lang_fr (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut_lang_fr: filename=gruut_lang_fr-2.0.2-py3-none-any.whl size=10968766 sha256=a2c3c5c43a80ac1ec0e216e109b4be9eae9441e3dfd9641baefad9ffae0bb15e\n",
            "  Stored in directory: /root/.cache/pip/wheels/db/21/be/d0436e3f1cf9bf38b9bb9b4a476399c77a1ab19f7172b45e19\n",
            "  Building wheel for pynndescent (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pynndescent: filename=pynndescent-0.5.10-py3-none-any.whl size=55622 sha256=bab15905432608dfd12c8c8955d3ac1bd4006c50d2ca41bbdf5b79296d463d76\n",
            "  Stored in directory: /root/.cache/pip/wheels/4a/38/5d/f60a40a66a9512b7e5e83517ebc2d1b42d857be97d135f1096\n",
            "  Building wheel for gruut (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut: filename=gruut-2.2.3-py3-none-any.whl size=75799 sha256=a77ae9f35f9e4b72f0683d891d1b72ab2660f41dd8eed51137cb0041a20b4895\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/57/a8/f9de532daf5214f53644f20f3a9e6f69269453c87df9c0a817\n",
            "  Building wheel for jsonmerge (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jsonmerge: filename=jsonmerge-1.9.1-py3-none-any.whl size=19363 sha256=10421adf8bd0d27cf0c68d4a2d09c93b94e48666bb4ae34ece07436a7f651471\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/7b/f8/fa28b738374fcf4f8e39c3c2dbeb3a02a8e380e57b6f9ab567\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13707 sha256=7a39cf958bb62d00ecfb26c4102201a91cf3bf2f7fa3468fcf6596e461ae9457\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8791 sha256=2b93265600d7745ab57fe3f09f0c753e8a6ff86dc2114f98865c9840f5a4c660\n",
            "  Stored in directory: /root/.cache/pip/wheels/e7/f3/22/152153d6eb222ee7a56ff8617d80ee5207207a8c00a7aab794\n",
            "Successfully built TTS bnunicodenormalizer umap-learn unidic-lite bnnumerizer encodec gruut-ipa gruut_lang_de gruut_lang_en gruut_lang_es gruut_lang_fr pynndescent gruut jsonmerge docopt pathtools\n",
            "Installing collected packages: unidic-lite, trampoline, tokenizers, safetensors, resize-right, python-crfsuite, pathtools, mecab-python3, jamo, gruut_lang_fr, gruut_lang_es, gruut_lang_en, gruut_lang_de, docopt, boltons, bnunicodenormalizer, bnnumerizer, bangla, smmap, setproctitle, sentry-sdk, pysbd, pypinyin, numpy, num2words, networkx, llvmlite, jsonlines, inflect, gruut-ipa, ftfy, einops, docker-pycreds, cython, coqpit, anyascii, numba, jsonmerge, huggingface-hub, gitdb, g2pkk, dateparser, transformers, gruut, GitPython, wandb, pynndescent, librosa, umap-learn, torchsde, torchdiffeq, kornia, clip-anytorch, clean-fid, accelerate, trainer, k-diffusion, encodec, TTS\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.22.4\n",
            "    Uninstalling numpy-1.22.4:\n",
            "      Successfully uninstalled numpy-1.22.4\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.1\n",
            "    Uninstalling networkx-3.1:\n",
            "      Successfully uninstalled networkx-3.1\n",
            "  Attempting uninstall: llvmlite\n",
            "    Found existing installation: llvmlite 0.39.1\n",
            "    Uninstalling llvmlite-0.39.1:\n",
            "      Successfully uninstalled llvmlite-0.39.1\n",
            "  Attempting uninstall: inflect\n",
            "    Found existing installation: inflect 6.0.5\n",
            "    Uninstalling inflect-6.0.5:\n",
            "      Successfully uninstalled inflect-6.0.5\n",
            "  Attempting uninstall: cython\n",
            "    Found existing installation: Cython 0.29.36\n",
            "    Uninstalling Cython-0.29.36:\n",
            "      Successfully uninstalled Cython-0.29.36\n",
            "  Attempting uninstall: numba\n",
            "    Found existing installation: numba 0.56.4\n",
            "    Uninstalling numba-0.56.4:\n",
            "      Successfully uninstalled numba-0.56.4\n",
            "  Attempting uninstall: librosa\n",
            "    Found existing installation: librosa 0.10.0.post2\n",
            "    Uninstalling librosa-0.10.0.post2:\n",
            "      Successfully uninstalled librosa-0.10.0.post2\n",
            "Successfully installed GitPython-3.1.32 TTS-0.15.6 accelerate-0.21.0 anyascii-0.3.2 bangla-0.0.2 bnnumerizer-0.0.2 bnunicodenormalizer-0.1.1 boltons-23.0.0 clean-fid-0.1.35 clip-anytorch-2.5.2 coqpit-0.0.17 cython-0.29.30 dateparser-1.1.8 docker-pycreds-0.4.0 docopt-0.6.2 einops-0.6.1 encodec-0.1.1 ftfy-6.1.1 g2pkk-0.1.2 gitdb-4.0.10 gruut-2.2.3 gruut-ipa-0.13.0 gruut_lang_de-2.0.0 gruut_lang_en-2.0.0 gruut_lang_es-2.0.0 gruut_lang_fr-2.0.2 huggingface-hub-0.16.4 inflect-5.6.0 jamo-0.4.1 jsonlines-1.2.0 jsonmerge-1.9.1 k-diffusion-0.0.15 kornia-0.6.12 librosa-0.10.0 llvmlite-0.40.1 mecab-python3-1.0.6 networkx-2.8.8 num2words-0.5.12 numba-0.57.0 numpy-1.22.0 pathtools-0.1.2 pynndescent-0.5.10 pypinyin-0.49.0 pysbd-0.3.4 python-crfsuite-0.9.9 resize-right-0.0.2 safetensors-0.3.1 sentry-sdk-1.28.1 setproctitle-1.3.2 smmap-5.0.0 tokenizers-0.13.3 torchdiffeq-0.2.3 torchsde-0.2.5 trainer-0.0.27 trampoline-0.1.2 transformers-4.30.2 umap-learn-0.5.1 unidic-lite-1.0.8 wandb-0.15.5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!git clone https://github.com/hrushik98/VITS-COQUI-TTS.git\n",
        "%cd /content/VITS-COQUI-TTS/\n",
        "! pip install -e ."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setting an output path"
      ],
      "metadata": {
        "id": "_28hINWTdQd8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# BaseDatasetConfig: defines name, formatter and path of the dataset.\n",
        "from TTS.tts.configs.shared_configs import BaseDatasetConfig\n",
        "\n",
        "output_path = \"/content/MyTTSdata\"\n",
        "if not os.path.exists(output_path):\n",
        "    os.makedirs(output_path)"
      ],
      "metadata": {
        "id": "IbkyoY6NK2IM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For preparing metadata.csv\n",
        "- You can use your own logic to do this or if you want to do it the way I did, Upload the audio files into MyTTSdata/wavs\n",
        "- upload all the transcripts of the audio files into a folder called as texts (create it first in \"/content\")\n",
        "- run this below cell to generate a metadata.csv file in /content\n",
        "- drag and drop the metadata.csv file into /content/MyTTSdata\n",
        "\n",
        "- Now your MyTTSdata folder should have these files:\n",
        "- sub-folder named as \"wavs\" with the .wavs of all the audios\n",
        "- a \"metadata.csv\" file"
      ],
      "metadata": {
        "id": "h8k2PU8gdKlL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It should look something like this"
      ],
      "metadata": {
        "id": "fIBAPp_FqbBR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "Uc-ClzmcqX0e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#run this to connect to google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPg73_IXqJqy",
        "outputId": "04e67527-98ae-47d4-f7e8-ce74d2ea58c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# uncomment this if you want to use this code\n",
        "# %cd /content\n",
        "\n",
        "# import os\n",
        "# import csv\n",
        "\n",
        "# texts = os.listdir(\"/content/texts\")\n",
        "\n",
        "# for i in range(0, len(texts)):\n",
        "#     with open(f\"/content/texts/{texts[i]}\", \"r\") as f:\n",
        "#         text = f.read()\n",
        "#         print(text)\n",
        "\n",
        "#         with open(\"metadata.csv\", \"a\") as f:\n",
        "#             datai = csv.writer(f)\n",
        "#             col1 = f\"{texts[i][:-4]}|{text}|{text}\"\n",
        "#             datai.writerow([col1])"
      ],
      "metadata": {
        "id": "QWiqzmQHSGIo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_config = BaseDatasetConfig(\n",
        "    formatter=\"ljspeech\", meta_file_train=\"/content/MyTTSdata/metadata.csv\", path=os.path.join(output_path, \"/content/MyTTSdata/\")\n",
        ")"
      ],
      "metadata": {
        "id": "9RBu6-vMK-yE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from TTS.tts.models.vits import Vits, VitsArgs, VitsAudioConfig, CharactersConfig\n",
        "from TTS.tts.configs.vits_config import VitsConfig\n",
        "from TTS.tts.models.vits import Vits"
      ],
      "metadata": {
        "id": "kUAw8K8BOoce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "setting audio config and training config file"
      ],
      "metadata": {
        "id": "_bz-jhpceX7q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "audio_config = VitsAudioConfig(\n",
        "    sample_rate=22050, win_length=1024, hop_length=256, num_mels=80, mel_fmin=0, mel_fmax=None\n",
        ")\n",
        "config = VitsConfig(\n",
        "    batch_size=32,\n",
        "    eval_batch_size=16,\n",
        "    num_loader_workers=4,\n",
        "    num_eval_loader_workers=4,\n",
        "    run_eval=True,\n",
        "    test_delay_epochs=-1,\n",
        "    epochs=2,\n",
        "    text_cleaner=\"phoneme_cleaners\",\n",
        "    use_phonemes=True,\n",
        "    phoneme_language=\"en-us\",\n",
        "    phoneme_cache_path=os.path.join(output_path, \"phoneme_cache\"),\n",
        "    print_step=25,\n",
        "    print_eval=False,\n",
        "    mixed_precision=True,\n",
        "    output_path=output_path,\n",
        "    datasets=[dataset_config],\n",
        ")"
      ],
      "metadata": {
        "id": "OoF3FVlEK-vY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from TTS.utils.audio import AudioProcessor\n",
        "ap = AudioProcessor.init_from_config(config)\n",
        "ap.sample_rate = 22050\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DGyJs3O3K-nP",
        "outputId": "a62b1fce-8abb-4b93-d2ee-39b3b05cc217"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " > Setting up Audio Processor...\n",
            " | > sample_rate:22050\n",
            " | > resample:False\n",
            " | > num_mels:80\n",
            " | > log_func:np.log10\n",
            " | > min_level_db:0\n",
            " | > frame_shift_ms:None\n",
            " | > frame_length_ms:None\n",
            " | > ref_level_db:None\n",
            " | > fft_size:1024\n",
            " | > power:None\n",
            " | > preemphasis:0.0\n",
            " | > griffin_lim_iters:None\n",
            " | > signal_norm:None\n",
            " | > symmetric_norm:None\n",
            " | > mel_fmin:0\n",
            " | > mel_fmax:None\n",
            " | > pitch_fmin:None\n",
            " | > pitch_fmax:None\n",
            " | > spec_gain:20.0\n",
            " | > stft_pad_mode:reflect\n",
            " | > max_norm:1.0\n",
            " | > clip_norm:True\n",
            " | > do_trim_silence:False\n",
            " | > trim_db:60\n",
            " | > do_sound_norm:False\n",
            " | > do_amp_to_db_linear:True\n",
            " | > do_amp_to_db_mel:True\n",
            " | > do_rms_norm:False\n",
            " | > db_level:None\n",
            " | > stats_path:None\n",
            " | > base:10\n",
            " | > hop_length:256\n",
            " | > win_length:1024\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from TTS.tts.utils.text.tokenizer import TTSTokenizer\n",
        "tokenizer, config = TTSTokenizer.init_from_config(config)"
      ],
      "metadata": {
        "id": "MRazeoRCIxfW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#never set the eval_split to false\n",
        "\n",
        "#use this if you have less number of audio files that cannot be split into eval_split\n",
        "\n",
        "from TTS.tts.datasets import load_tts_samples\n",
        "train_samples, eval_samples = load_tts_samples(\n",
        "    dataset_config,\n",
        "    eval_split=True,\n",
        "    eval_split_size = 0.08333333333333333,\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yw5iMyT7I12_",
        "outputId": "326364a2-e52f-4293-ada4-906696b124bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Found 20 files in /content/MyTTSdata\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#use this if you have a bigger dataset and can split into eval batch\n",
        "\n",
        "# from TTS.tts.datasets import load_tts_samples\n",
        "# train_samples, eval_samples = load_tts_samples(\n",
        "#     dataset_config,\n",
        "#     eval_split=True,\n",
        "#     eval_split_max_size=config.eval_split_max_size,\n",
        "#     eval_split_size=config.eval_split_size,\n",
        "\n",
        "# )"
      ],
      "metadata": {
        "id": "JKWidHetrAv-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Vits(config, ap, tokenizer, speaker_manager=None)"
      ],
      "metadata": {
        "id": "ds5AhtrNI26h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from trainer import Trainer, TrainerArgs\n",
        "trainer = Trainer(\n",
        "    TrainerArgs(), config, output_path, model=model, train_samples=train_samples, eval_samples=eval_samples\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kdgJUXCAI323",
        "outputId": "65ec69bb-c80a-46f6-d0ae-72fe02a36247"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " > Training Environment:\n",
            " | > Current device: 0\n",
            " | > Num. of GPUs: 1\n",
            " | > Num. of CPUs: 2\n",
            " | > Num. of Torch Threads: 1\n",
            " | > Torch seed: 54321\n",
            " | > Torch CUDNN: True\n",
            " | > Torch CUDNN deterministic: False\n",
            " | > Torch CUDNN benchmark: False\n",
            " > Start Tensorboard: tensorboard --logdir=/content/MyTTSdata/run-July-15-2023_01+17PM-0000000\n",
            "\n",
            " > Model has 83059180 parameters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.fit()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6HkqKDFI5Am",
        "outputId": "10b5321a-f89a-48f5-bd4f-da1e6784bd9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 0/2\u001b[0m\n",
            " --> /content/MyTTSdata/run-July-15-2023_01+17PM-0000000\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\u001b[1m > TRAINING (2023-07-15 13:17:22) \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 19\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 39\n",
            " | > Min text length: 12\n",
            " | > Avg text length: 28.0\n",
            " | \n",
            " | > Max audio length: 56838.0\n",
            " | > Min audio length: 30150.0\n",
            " | > Avg audio length: 42873.36842105263\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:641: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
            "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:862.)\n",
            "  return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore[attr-defined]\n",
            "\n",
            "\u001b[1m   --> STEP: 0/1 -- GLOBAL_STEP: 0\u001b[0m\n",
            "     | > loss_disc: 6.021332740783691  (6.021332740783691)\n",
            "     | > loss_disc_real_0: 1.0415648221969604  (1.0415648221969604)\n",
            "     | > loss_disc_real_1: 1.0164521932601929  (1.0164521932601929)\n",
            "     | > loss_disc_real_2: 0.9977254867553711  (0.9977254867553711)\n",
            "     | > loss_disc_real_3: 1.0030697584152222  (1.0030697584152222)\n",
            "     | > loss_disc_real_4: 1.005555272102356  (1.005555272102356)\n",
            "     | > loss_disc_real_5: 0.9559569954872131  (0.9559569954872131)\n",
            "     | > loss_0: 6.021332740783691  (6.021332740783691)\n",
            "     | > grad_norm_0: 0  (0)\n",
            "     | > loss_gen: 6.020523548126221  (6.020523548126221)\n",
            "     | > loss_kl: 158.5172576904297  (158.5172576904297)\n",
            "     | > loss_feat: 0.26749637722969055  (0.26749637722969055)\n",
            "     | > loss_mel: 96.79106140136719  (96.79106140136719)\n",
            "     | > loss_duration: 1.8792691230773926  (1.8792691230773926)\n",
            "     | > amp_scaler: 32768.0  (32768.0)\n",
            "     | > loss_1: 263.4756164550781  (263.4756164550781)\n",
            "     | > grad_norm_1: 0  (0)\n",
            "     | > current_lr_0: 0.0002 \n",
            "     | > current_lr_1: 0.0002 \n",
            "     | > step_time: 8.7854  (8.785376071929932)\n",
            "     | > loader_time: 4.6946  (4.694610834121704)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:139: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 1\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 24\n",
            " | > Min text length: 24\n",
            " | > Avg text length: 24.0\n",
            " | \n",
            " | > Max audio length: 39414.0\n",
            " | > Min audio length: 39414.0\n",
            " | > Avg audio length: 39414.0\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 0.22967004776000977 \u001b[0m(+0)\n",
            "     | > avg_loss_disc: 6.021605491638184 \u001b[0m(+0)\n",
            "     | > avg_loss_disc_real_0: 1.041588306427002 \u001b[0m(+0)\n",
            "     | > avg_loss_disc_real_1: 1.0164965391159058 \u001b[0m(+0)\n",
            "     | > avg_loss_disc_real_2: 0.9975182414054871 \u001b[0m(+0)\n",
            "     | > avg_loss_disc_real_3: 1.0033607482910156 \u001b[0m(+0)\n",
            "     | > avg_loss_disc_real_4: 1.0055900812149048 \u001b[0m(+0)\n",
            "     | > avg_loss_disc_real_5: 0.9560434818267822 \u001b[0m(+0)\n",
            "     | > avg_loss_0: 6.021605491638184 \u001b[0m(+0)\n",
            "     | > avg_loss_gen: 6.020498275756836 \u001b[0m(+0)\n",
            "     | > avg_loss_kl: 159.24618530273438 \u001b[0m(+0)\n",
            "     | > avg_loss_feat: 0.2969387471675873 \u001b[0m(+0)\n",
            "     | > avg_loss_mel: 103.61222839355469 \u001b[0m(+0)\n",
            "     | > avg_loss_duration: 2.220001459121704 \u001b[0m(+0)\n",
            "     | > avg_loss_1: 271.3958435058594 \u001b[0m(+0)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/VITS-COQUI-TTS/TTS/tts/models/vits.py:1455: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3571.)\n",
            "  test_figures[\"{}-alignment\".format(idx)] = plot_alignment(alignment.T, output_fig=False)\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 0.22967004776000977 \u001b[0m(+0.0)\n",
            "     | > avg_loss_disc: 6.021605491638184 \u001b[0m(+0.0)\n",
            "     | > avg_loss_disc_real_0: 1.041588306427002 \u001b[0m(+0.0)\n",
            "     | > avg_loss_disc_real_1: 1.0164965391159058 \u001b[0m(+0.0)\n",
            "     | > avg_loss_disc_real_2: 0.9975182414054871 \u001b[0m(+0.0)\n",
            "     | > avg_loss_disc_real_3: 1.0033607482910156 \u001b[0m(+0.0)\n",
            "     | > avg_loss_disc_real_4: 1.0055900812149048 \u001b[0m(+0.0)\n",
            "     | > avg_loss_disc_real_5: 0.9560434818267822 \u001b[0m(+0.0)\n",
            "     | > avg_loss_0: 6.021605491638184 \u001b[0m(+0.0)\n",
            "     | > avg_loss_gen: 6.020498275756836 \u001b[0m(+0.0)\n",
            "     | > avg_loss_kl: 159.24618530273438 \u001b[0m(+0.0)\n",
            "     | > avg_loss_feat: 0.2969387471675873 \u001b[0m(+0.0)\n",
            "     | > avg_loss_mel: 103.61222839355469 \u001b[0m(+0.0)\n",
            "     | > avg_loss_duration: 2.220001459121704 \u001b[0m(+0.0)\n",
            "     | > avg_loss_1: 271.3958435058594 \u001b[0m(+0.0)\n",
            "\n",
            " > BEST MODEL : /content/MyTTSdata/run-July-15-2023_01+17PM-0000000/best_model_1.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 1/2\u001b[0m\n",
            " --> /content/MyTTSdata/run-July-15-2023_01+17PM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-07-15 13:17:47) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.33202481269836426 \u001b[0m(+0.10235476493835449)\n",
            "     | > avg_loss_disc:\u001b[92m 6.021486282348633 \u001b[0m(-0.00011920928955078125)\n",
            "     | > avg_loss_disc_real_0:\u001b[92m 1.0415163040161133 \u001b[0m(-7.200241088867188e-05)\n",
            "     | > avg_loss_disc_real_1:\u001b[91m 1.0166192054748535 \u001b[0m(+0.0001226663589477539)\n",
            "     | > avg_loss_disc_real_2:\u001b[92m 0.9974833130836487 \u001b[0m(-3.4928321838378906e-05)\n",
            "     | > avg_loss_disc_real_3:\u001b[91m 1.003432273864746 \u001b[0m(+7.152557373046875e-05)\n",
            "     | > avg_loss_disc_real_4:\u001b[92m 1.0053625106811523 \u001b[0m(-0.0002275705337524414)\n",
            "     | > avg_loss_disc_real_5:\u001b[91m 0.9560642242431641 \u001b[0m(+2.0742416381835938e-05)\n",
            "     | > avg_loss_0:\u001b[92m 6.021486282348633 \u001b[0m(-0.00011920928955078125)\n",
            "     | > avg_loss_gen:\u001b[92m 6.020497798919678 \u001b[0m(-4.76837158203125e-07)\n",
            "     | > avg_loss_kl:\u001b[91m 162.7445068359375 \u001b[0m(+3.498321533203125)\n",
            "     | > avg_loss_feat:\u001b[92m 0.1434541493654251 \u001b[0m(-0.15348459780216217)\n",
            "     | > avg_loss_mel:\u001b[92m 78.226806640625 \u001b[0m(-25.385421752929688)\n",
            "     | > avg_loss_duration:\u001b[92m 2.0377585887908936 \u001b[0m(-0.18224287033081055)\n",
            "     | > avg_loss_1:\u001b[92m 249.1730194091797 \u001b[0m(-22.222824096679688)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 0.33202481269836426 \u001b[0m(+0.0)\n",
            "     | > avg_loss_disc: 6.021486282348633 \u001b[0m(+0.0)\n",
            "     | > avg_loss_disc_real_0: 1.0415163040161133 \u001b[0m(+0.0)\n",
            "     | > avg_loss_disc_real_1: 1.0166192054748535 \u001b[0m(+0.0)\n",
            "     | > avg_loss_disc_real_2: 0.9974833130836487 \u001b[0m(+0.0)\n",
            "     | > avg_loss_disc_real_3: 1.003432273864746 \u001b[0m(+0.0)\n",
            "     | > avg_loss_disc_real_4: 1.0053625106811523 \u001b[0m(+0.0)\n",
            "     | > avg_loss_disc_real_5: 0.9560642242431641 \u001b[0m(+0.0)\n",
            "     | > avg_loss_0: 6.021486282348633 \u001b[0m(+0.0)\n",
            "     | > avg_loss_gen: 6.020497798919678 \u001b[0m(+0.0)\n",
            "     | > avg_loss_kl: 162.7445068359375 \u001b[0m(+0.0)\n",
            "     | > avg_loss_feat: 0.1434541493654251 \u001b[0m(+0.0)\n",
            "     | > avg_loss_mel: 78.226806640625 \u001b[0m(+0.0)\n",
            "     | > avg_loss_duration: 2.0377585887908936 \u001b[0m(+0.0)\n",
            "     | > avg_loss_1: 249.1730194091797 \u001b[0m(+0.0)\n",
            "\n",
            " > BEST MODEL : /content/MyTTSdata/run-July-15-2023_01+17PM-0000000/best_model_2.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import glob, os\n",
        "output_path = \"/content/MyTTSdata\"\n",
        "ckpts = sorted([f for f in glob.glob(output_path+\"/*/*.pth\")])\n",
        "configs = sorted([f for f in glob.glob(output_path+\"/*/*.json\")])"
      ],
      "metadata": {
        "id": "9lGGPZipVVIZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!tts --text \"Text for TTS\" \\\n",
        "      --model_path $test_ckpt \\\n",
        "      --config_path $test_config \\\n",
        "      --out_path out.wav"
      ],
      "metadata": {
        "id": "gAtZopigVVIa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import IPython\n",
        "IPython.display.Audio(\"out.wav\")"
      ],
      "metadata": {
        "id": "1F6kfMiYVD0S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2lGDMgTDK-c4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}